{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **The eighth in-class-exercise (20 points in total, 10/29/2020)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this exercise is from the dataset you created from assignment three. Please perform answer the following questions based on your data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) (10 points) Write a python program to extract the sentiment related terms from the corpus. You may use python package such as polyglot or external lexicon resources in the question. Rank the sentiment related terms by frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment related terms ranked by term frequency are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dark</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>many</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>best</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>much</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>hated</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>wise</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>fortunate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>magnificent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>subtle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           words    tf  polarity\n",
       "0           good  52.0  0.700000\n",
       "1           dark  33.0 -0.150000\n",
       "2           many  33.0  0.500000\n",
       "3           best  32.0  1.000000\n",
       "4           much  31.0  0.200000\n",
       "..           ...   ...       ...\n",
       "395        hated   1.0 -0.900000\n",
       "396         wise   1.0  0.700000\n",
       "397    fortunate   1.0  0.400000\n",
       "398  magnificent   1.0  1.000000\n",
       "399       subtle   1.0 -0.333333\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "from textblob import TextBlob\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\Raheyma Arshad\\Desktop\\Output_CSV.csv\")\n",
    "data = data[['review']]\n",
    "\n",
    "# Text Preprocessing\n",
    "data['review'] = data['review'].str.replace('[^\\w\\s]','')\n",
    "data['review'] = data['review'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "data['review'] = data['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "data['review'] = data['review'].apply(lambda x: nltk.word_tokenize(x))\n",
    "\n",
    "# Calculate the frequency of all the terms.\n",
    "term_freq = (data['review']).apply(lambda x: pd.value_counts(x)).sum(axis = 0).reset_index()\n",
    "term_freq.columns = ['words', 'tf']\n",
    "\n",
    "# Find the polarity of each term.\n",
    "term_freq['polarity'] = term_freq['words'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "# Remove terms with polarity = 0.0 because they do not have any sentiment associated with them.\n",
    "sentiment_related_terms = term_freq.loc[term_freq['polarity'] != 0].sort_values(by='tf', ascending=False)\n",
    "sentiment_related_terms = sentiment_related_terms.reset_index(drop=True)\n",
    "print('The sentiment related terms ranked by term frequency are:')\n",
    "sentiment_related_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) (10 points) Compare the performance of the following tools in sentiment identification: TextBlob (https://textblob.readthedocs.io/en/dev/), VADER (https://github.com/cjhutto/vaderSentiment), TFIDF-based Support Vector Machine (SVM) (Split your data into training and testing data). Take your own annotation as the standard answers. \n",
    "\n",
    "Reference code: https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TEXTBLOB SENTIMENT IDENTIFICATION: \n",
      "\n",
      "  document_id sentiment predicted sentiment\n",
      "0        rev1  Positive             Neutral\n",
      "1        rev2  Positive            Positive\n",
      "2        rev3  Positive             Neutral\n",
      "3        rev4  Positive            Negative\n",
      "4        rev5  Positive             Neutral\n",
      "\n",
      " The accuracy of the TextBlob sentiment identification is: 39.0\n",
      "The f1-score of the TextBlob sentiment identification is: 0.3782789979973078\n",
      "\n",
      " VADER SENTIMENT IDENTIFICATION: \n",
      "\n",
      "  document_id sentiment predicted sentiment\n",
      "0        rev1  Positive            Positive\n",
      "1        rev2  Positive            Positive\n",
      "2        rev3  Positive            Positive\n",
      "3        rev4  Positive            Positive\n",
      "4        rev5  Positive            Positive\n",
      "\n",
      " The accuracy of the VADER sentiment identification is: 55.00000000000001\n",
      "The f1-score of the VADER sentiment identification is: 0.34931752873563227\n",
      "\n",
      " TFIDF-BASED SVM SENTIMENT IDENTIFICATION: \n",
      "\n",
      "   document_id sentiment predicted sentiment\n",
      "18       rev19   Neutral            Negative\n",
      "42       rev43  Positive            Negative\n",
      "68       rev69  Negative            Negative\n",
      "23       rev24  Negative            Negative\n",
      "72       rev73  Positive            Positive\n",
      "\n",
      " The accuracy of the TFIDF-based SVM sentiment identification is: 70.0\n",
      "The f1-score of the TFIDF-based SVM sentiment identification is: 0.44871794871794873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-157-3820248bb4d6>:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['predicted sentiment'] = svm.predict(test['clean_text'])\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "############################################################################################################################\n",
    "# TEXTBLOB\n",
    "\n",
    "data2 = pd.read_csv(r\"C:\\Users\\Raheyma Arshad\\Desktop\\Annotated Data.csv\")\n",
    "data2['polarity'] = data2['clean_text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "data2['predicted sentiment'] = pd.cut(data2['polarity'], bins=5, labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "def sentiment(x):\n",
    "    if x in [1, 2]:\n",
    "        return 'Negative'\n",
    "    if x == 3:\n",
    "        return 'Neutral'\n",
    "    if x in [4, 5]:\n",
    "        return 'Positive'\n",
    "\n",
    "data2['predicted sentiment'] = data2['predicted sentiment'].apply(lambda x: sentiment(x))\n",
    "print('\\n', 'TEXTBLOB SENTIMENT IDENTIFICATION:', '\\n')\n",
    "print(data2[['document_id', 'sentiment', 'predicted sentiment']].head(5))\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "textblob_accuracy = accuracy_score(data2['sentiment'], data2['predicted sentiment'])*100\n",
    "textblob_f1 = f1_score(data2['sentiment'], data2['predicted sentiment'], average='macro')\n",
    "\n",
    "print('\\n', 'The accuracy of the TextBlob sentiment identification is:', textblob_accuracy)\n",
    "print('The f1-score of the TextBlob sentiment identification is:', textblob_f1)\n",
    "\n",
    "############################################################################################################################\n",
    "# VADER\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "data3 = pd.read_csv(r\"C:\\Users\\Raheyma Arshad\\Desktop\\Annotated Data.csv\")\n",
    "data3['polarity'] = data2['clean_text'].apply(lambda x: vader.polarity_scores(x)['compound'])\n",
    "data3['predicted sentiment'] = pd.cut(data3['polarity'], bins=5, labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "data3['predicted sentiment'] = data3['predicted sentiment'].apply(lambda x: sentiment(x))\n",
    "print('\\n', 'VADER SENTIMENT IDENTIFICATION:', '\\n')\n",
    "print(data3[['document_id', 'sentiment', 'predicted sentiment']].head(5))\n",
    "\n",
    "vader_accuracy = accuracy_score(data3['sentiment'], data3['predicted sentiment'])*100\n",
    "vader_f1 = f1_score(data3['sentiment'], data3['predicted sentiment'], average='macro')\n",
    "\n",
    "print('\\n', 'The accuracy of the VADER sentiment identification is:', vader_accuracy)\n",
    "print('The f1-score of the VADER sentiment identification is:', vader_f1)\n",
    "\n",
    "############################################################################################################################\n",
    "# TFIDF-BASED SUPPORT VECTOR MACHINE (SVM)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data4 = pd.read_csv(r\"C:\\Users\\Raheyma Arshad\\Desktop\\Annotated Data.csv\")\n",
    "train, test = sklearn.model_selection.train_test_split(data4, train_size=0.8, test_size=0.2)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=100, \n",
    "                                           learning_rate='optimal', tol=None))])\n",
    "\n",
    "svm = pipeline.fit(train['clean_text'], train['sentiment'])\n",
    "test['predicted sentiment'] = svm.predict(test['clean_text'])\n",
    "\n",
    "print('\\n', 'TFIDF-BASED SVM SENTIMENT IDENTIFICATION:', '\\n')\n",
    "print(test[['document_id', 'sentiment', 'predicted sentiment']].head(5))\n",
    "\n",
    "svm_accuracy = accuracy_score(test['sentiment'], test['predicted sentiment'])*100\n",
    "svm_f1 = f1_score(test['sentiment'], test['predicted sentiment'], average='macro')\n",
    "\n",
    "print('\\n', 'The accuracy of the TFIDF-based SVM sentiment identification is:', svm_accuracy)\n",
    "print('The f1-score of the TFIDF-based SVM sentiment identification is:', svm_f1)\n",
    "\n",
    "############################################################################################################################\n",
    "# Your analysis here\n",
    "'''\n",
    "We conduct sentiment analysis using three tools: TextBlob, VADER and TF-IDF Based SVM. The performance of the models on the \n",
    "annotated data is measured using accuracy score and f1 score. \n",
    "\n",
    "TF-IDF Based SVM gives the best accuracy and f1 score, which means it is the best model for sentiment analysis. It was able \n",
    "to correctly identify 70% of the reviews in the test dataset. VADER performed better than TextBlob and was able to correctly\n",
    "identify 55% of the reviews. TextBlob performed the worst and was correct in only 39% of the cases. \n",
    "\n",
    "TextBlob finds words and phrases it can assign polarity to, and averages them all together for longer text. While VADER \n",
    "finds the sentiment score of a text by summing up the intensity of each word in the text. We can say that VADER is more\n",
    "thorough and thats why gives better results. SVM is even more thorough than the other two and thats why gives the best \n",
    "results.\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
